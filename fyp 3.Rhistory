deceptivetdmCorpus <- as.data.frame(as.matrix(deceptivetdm))
dterm_frequency <- rowSums(deceptivetdmCorpus)
dterm_frequency <- sort(dterm_frequency, decreasing = T)
dterm_frequency[1:10]
truthfultdm <- TermDocumentMatrix(tcorpus)
truthfultdmCorpus <- as.data.frame(as.matrix(truthfultdm))
tterm_frequency <- rowSums(truthfultdmCorpus)
tterm_frequency <- sort(tterm_frequency, decreasing = T)
tterm_frequency[1:10]
barplot(term_frequency[1:20], col = "tan", las = 2)
barplot(dterm_frequency[1:20], col = "tan", las = 2)
barplot(tdterm_frequency[1:20], col = "tan", las = 2)
barplot(tterm_frequency[1:20], col = "tan", las = 2)
View(charSparse)
chartrain=charSparse[train_ind,]
chartest=charSparse[-train_ind,]
StandardSparse = glm(deceptive~ ., data=chartrain, family="binomial")
PredictSparse = predict(StandardSparse, newdata=chartest, type="response")
table(chartest$deceptive, StandardSparse > 0.5)
charSparse
summary(StandardSparse)
summary(PredictSparse)
summary(PredictSRM)
table(test$deceptive, StandardRModel > 0.5)
table(test$deceptive, StandardRModel > 0.5)
test
StandardRModel = glm(deceptive ~ ., data=train, family="binomial")
PredictSRM = predict(StandardRModel, newdata=test, type="response")
table(test$deceptive, StandardRModel > 0.5)
train=testCorpus[train_ind,]
test=testCorpus[-train_ind,]
StandardRModel = glm(deceptive ~ ., data=train, family="binomial")
summary(StandardRModel)
PredictSRM = predict(StandardRModel, newdata=test, type="response")
table(test$deceptive, PredictSRM > 0.5)
table(chartest$deceptive, PredictSparse > 0.5)
StandardcharRM = glm(deceptive~ ., data=chartrain, family="binomial")
PredictcharRM = predict(StandardSparse, newdata=chartest, type="response")
table(chartest$deceptive, PredictcharRM > 0.5)
table(idftest$deceptive, PredictidfRM > 0.5)
View(tc)
tc[["4"]][["content"]]
library(quanteda)
TokenAll<- function(x){tokens(x, remove_numbers = FALSE, remove_punct = FALSE)}
PoScorpus  <- lapply(deceptive.opinion , TokenAll)
PoScorpus  <- lapply(deceptive.opinion$text , TokenAll)
View(PoScorpus)
PoScorpus[[4]][["text1"]]
punctToken = PoScorpus
PoScorpus = VCorpus(VectorSource(punctToken))
View(PoScorpus)
PoScorpus = tm_map(PoScorpus, content_transformer(tolower))
PoScorpus = tm_map(PoScorpus, PlainTextDocument)
PoScorpus = tm_map(PoScorpus, removeWords, c("hotel", "chicago", "hotels"))
PoScorpus = tm_map(PoScorpus, stemDocument)
View(PoScorpus)
View(PoScorpus)
punctdtm = DocumentTermMatrix(punctdtm)
punctdtm = DocumentTermMatrix(PoScorpus)
punctdtm
sparsepunctdtm = removeSparseTerms(punctdtm, 0.95)
sparsepunctdtm
View(sparsepunctdtm)
View(sparsepunctdtm)
sparsepunctdtm[["dimnames"]][["Terms"]]
View(punctdtm)
punctdtm[["dimnames"]][["Terms"]]
puncttdm = TermDocumentMatrix(PoScorpus)
View(puncttdm)
puncttdm[["dimnames"]][["Terms"]]
punctterm_frequency <- rowSums(puncttdm)term_frequency <- rowSums(tdmCorpus)
punctterm_frequency <- sort(punctterm_frequency, decreasing = T)
punctterm_frequency[1:10]
barplot(punctterm_frequency[1:10], col = "tan", las = 2)
punctterm_frequency <- rowSums(puncttdm)
punctterm_frequency <- sort(punctterm_frequency, decreasing = T)
punctterm_frequency[1:10]
barplot(punctterm_frequency[1:10], col = "tan", las = 2)
punctterm_frequency <- rowSums(puncttdm)
punctdtm
puncttdm
sparsepunctdtm
punctterm_frequency <- rowSums(puncttdm)
puncttdm[["dimnames"]][["Terms"]]
sparsepunctdtm
puncttdm[["dimnames"]][["Terms"]]
punctterm_frequency <- rowSums(puncttdm)
save.image("~/FYP_LR_Prototype/fyp.RData")
save(StandardidfRM, file = "resultsidf_df.RData")
save(StandardcharRM, file = "resultschar_df.RData")
save(summary.glm(StandardidfRM), file = "resultsidf_df.RData")
save(summary.glm(StandardidfRM), file = "resultsidf_df.RData")
resultsidf_df = summary.glm(StandardidfRM)
resultschar_df = summary.glm(StandardcharRM)
save(resultsidf_df, file = "resultsidf_df.RData")
save(resultschar_df, file = "resultschar_df.RData")
save(resultschar_df, file = "resultschar_df.LDA")
save(resultschar_df, file = "resultschar_df.LDA")
save(results_df, filename="results_df.LDA")
save(results_df, file="results_df.LDA")
save(resultsB_df, file = "resultsB_df.LDA")
View(annotateDocuments)
PartofSpeechtext = annotateDocuments(deceptive.opinion$text)
annotationText <- lapply(deceptive.opinion$text, annotateDocuments)
View(Tagcorpus)
annotationText <- lapply(Tagcorpus, annotateDocuments)
annotateDocuments = annotator_pipeline <- Annotator_Pipeline(
sent_token_annotator,
word_token_annotator,
pos_tag_annotator
)
rm(POS_token_annotator)
pos_tag_annotator <- Maxent_POS_Tag_Annotator()
library(openNLP)
pos_tag_annotator <- Maxent_POS_Tag_Annotator()
View(annotateDocuments)
View(annotateDocuments)
annotateDocuments = annotator_pipeline <- Annotator_Pipeline(
sent_token_annotator,
word_token_annotator,
pos_tag_annotator
)
View(annotator_pipeline)
annotationText <- lapply(Tagcorpus, annotateDocuments)
annotator_pipeline <- Annotator_Pipeline(
sent_token_annotator,
word_token_annotator,
pos_tag_annotator
)
View(annotateDocuments)
annotationText <- lapply(Tagcorpus, annotateDocuments)
annotateDocuments <- function(doc, pos_filter = NULL) {
doc <- as.String(doc)
doc_with_annotations <- annotate(doc, annotator_pipeline)
tags <- sapply(subset(doc_with_annotations, type=="word")$features, `[[`, "POS")
tokens <- doc[subset(doc_with_annotations, type=="word")]
if (!is.null(pos_filter)) {
res <- tokens[tags %in% pos_filter]
} else {
res <- paste0(tokens, "_", tags)
}
res <- paste(res, collapse = " ")
return(res)
}
annotationText <- lapply(Tagcorpus, annotateDocuments)
annotateDocuments
View(annotateDocuments)
View(annotator_pipeline)
wordSentAnnotate = function(x){annotate(x, list(sent_token_annotator, word_token_annotator))}
annotationText <- lapply(Tagcorpus, wordSentAnnotate)
annotationText <- lapply(deceptive.opinion$text, wordSentAnnotate)
tagtext = data.frame(text = sapply(Tagcorpus, as.character), stringsAsFactors = FALSE)
View(tagtext)
tagtext = data.frame(text = sapply(Tagcorpus, as.String), stringsAsFactors = FALSE)
View(tagtext)
annotationText <- lapply(tagtext, wordSentAnnotate)
save.image("~/FYP_LR_Prototype/fyp2.RData")
library(openNLP)
library(quanteda)
library(wordcloud)
library(tokenizers)
library(tm)
library(SnowballC)
library(gamlr)
library(dplyr)
library(openNLP)
library(glm2)
library(tidyr)
library(tm)
library(tidyselect)
library(tokenizers)
library(wordcloud)
library(dplyr)
library(ggplot2)
library(ggplot2)
library(topicmodels)
library(dplyr)
library(tokenizers)
testString = "Hi, my name is Nkem."
a2 <- annotate(testString, list(sent_token_annotator, word_token_annotator))
s=as.String(testString)
s
a2 <- annotate(s, list(sent_token_annotator, word_token_annotator))
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator <- Maxent_POS_Tag_Annotator()
a2 <- annotate(s, list(sent_token_annotator, word_token_annotator))
detach("package:NLP", unload = TRUE)
library(NLP)
a2 <- NLP::annotate(s, list(sent_token_annotator, word_token_annotator))
a2
wordSentAnnotate = function(x){NLP::annotate(x, list(sent_token_annotator, word_token_annotator))}
annotationText <- lapply(tagtext, wordSentAnnotate)
View(annotationText)
annotationText[["text"]][[3]]
annotationText[["text"]][[3]][[1]][[1]][[1]][[1]][[1]][[1]]
View(a2)
a2[[1]]
a2[[1]][[1]][[1]][[1]][[1]][[1]]
a2[[7]][[1]]
a2
library(qdap)
a2 <- annotate(Tagcorpus, list(sent_token_annotator, word_token_annotator))
library(qdap)
library(NLP)
library(tokenizers)
library(dplyr)
library(topicmodels)
library(ggplot2)
library(ggplot2)
library(dplyr)
library(wordcloud)
library(tokenizers)
library(tidyselect)
library(tm)
library(tidyr)
library(glm2)
library(openNLP)
library(dplyr)
library(gamlr)
library(SnowballC)
library(tm)
library(tokenizers)
library(wordcloud)
library(qdap)
annotateDocuments <- function(doc, pos_filter = NULL) {
doc <- as.String(doc)
doc_with_annotations <- NLP::annotate(doc, annotator_pipeline)
tags <- sapply(subset(doc_with_annotations, type=="word")$features, `[[`, "POS")
tokens <- doc[subset(doc_with_annotations, type=="word")]
if (!is.null(pos_filter)) {
res <- tokens[tags %in% pos_filter]
} else {
res <- paste0(tokens, "_", tags)
}
res <- paste(res, collapse = " ")
return(res)
}
annotatedCorpus <- lapply(deceptive.opinion$text, annotateDocuments)
View(annotationText)
View(annotator_pipeline)
annotator_pipeline <- Annotator_Pipeline(
sent_token_annotator,
word_token_annotator,
pos_tag_annotator
)
annotatedCorpus <- lapply(s, annotateDocuments)
annotatedCorpus <- lapply(tagtext, annotateDocuments)
annotated_corpus <- lapply(texts(tagtext), annotateDocuments)
annotated_corpus <- lapply((tagtext), annotateDocuments)
View(wordSentAnnotate)
tagpos = function(x){annotate(x, pos_tag_annotator, a2)}
a2 <- lapply(tagtext, wordSentAnnotate)
tagtext = data.frame(text = sapply(Tagcorpus, as.String), stringsAsFactors = FALSE)
a2 <- lapply(tagtext, wordSentAnnotate)
annotationText <- lapply(tagtext, wordSentAnnotate)
View(wordSentAnnotate)
wordSentAnnotate = function(x){annotate(x, list(sent_token_annotator, word_token_annotator))}
annotationText <- lapply(Tagcorpus, wordSentAnnotate)
wordSentAnnotate = function(x){NLP::annotate(x, list(sent_token_annotator, word_token_annotator))}
annotationText <- lapply(tagtext, wordSentAnnotate)
View(tagtext)
library(openNLPdata)
annotatedCorpus <- lapply(tagtext, annotateDocuments)
annotateDocuments <- function(doc, pos_filter = NULL) {
doc <- as.String(doc)
doc_with_annotations <- NLP::annotate(doc, annotator_pipeline)
tags <- sapply(subset(doc_with_annotations, type=="word")$features, `[[`, "POS")
tokens <- doc[subset(doc_with_annotations, type=="word")]
if (!is.null(pos_filter)) {
res <- tokens[tags %in% pos_filter]
} else {
res <- paste0(tokens, "_", tags)
}
res <- paste(res, collapse = " ")
return(res)
}
detach("package:ggplot2", unload = TRUE)
annotateDocuments <- function(doc, pos_filter = NULL) {
doc <- as.String(doc)
doc_with_annotations <- annotate(doc, annotator_pipeline)
tags <- sapply(subset(doc_with_annotations, type=="word")$features, `[[`, "POS")
tokens <- doc[subset(doc_with_annotations, type=="word")]
if (!is.null(pos_filter)) {
res <- tokens[tags %in% pos_filter]
} else {
res <- paste0(tokens, "_", tags)
}
res <- paste(res, collapse = " ")
return(res)
}
a2 <- annotate(s, list(sent_token_annotator, word_token_annotator))
pos_tag_annotator <- Maxent_POS_Tag_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
sent_token_annotator <- Maxent_Sent_Token_Annotator()
a2 <- annotate(s, list(sent_token_annotator, word_token_annotator))
annotatedCorpus <- lapply(tagtext, annotateDocuments)
annotationText <- lapply(tagtext, wordSentAnnotate)
a2 <- lapply(tagtext, wordSentAnnotate)
annotator_pipeline <- Annotator_Pipeline(
sent_token_annotator,
word_token_annotator,
pos_tag_annotator
)
annotateDocuments <- function(doc, pos_filter = NULL) {
doc <- as.String(doc)
doc_with_annotations <- annotate(doc, annotator_pipeline)
tags <- sapply(subset(doc_with_annotations, type=="word")$features, `[[`, "POS")
tokens <- doc[subset(doc_with_annotations, type=="word")]
if (!is.null(pos_filter)) {
res <- tokens[tags %in% pos_filter]
} else {
res <- paste0(tokens, "_", tags)
}
res <- paste(res, collapse = " ")
return(res)
}
annotated_corpus <- lapply(Tagcorpus, annotateDocuments)
annotated_corpus
View(annotated_corpus)
Postext <- lapply(tagtext, tagpos)
a3 <- lapply(tagtext, tagpos)
a3 <- annotate(Tagcorpus, pos_tag_annotator, a2)
a2 <- lapply(tagtext, wordSentAnnotate)
a3 <- annotate(Tagcorpus, pos_tag_annotator, a2)
tagpos = function(x){annotate(x, pos_tag_annotator, a2)}
a3 <- lapply(tagtext, tagpos)
annotated_corpus[["92"]]
taggedCorpus = VCorpus(VectorSource(annotated_corpus))
taggedCorpus = tm_map(taggedCorpus, content_transformer(tolower))
taggedCorpus = tm_map(taggedCorpus, PlainTextDocument)
taggedCorpus = tm_map(taggedCorpus, removeWords, stopwords("en"))
taggedCorpus = tm_map(taggedCorpus, removePunctuation)
taggedCorpus = tm_map(taggedCorpus, stemDocument)
View(taggedCorpus)
taggedCorpus = VCorpus(VectorSource(deceptive.opinion$text))
taggedCorpus = tm_map(taggedCorpus, content_transformer(tolower))
taggedCorpus = tm_map(taggedCorpus, PlainTextDocument)
taggedCorpus = tm_map(taggedCorpus, removeWords, stopwords("en"))
taggedCorpus = tm_map(taggedCorpus, removePunctuation)
View(taggedCorpus)
annotated_corpus <- lapply(taggedCorpus, annotateDocuments)
View(taggedCorpus)
View(annotated_corpus)
taggedCorpus = VCorpus(VectorSource(deceptive.opinion$text))
taggedCorpus = tm_map(taggedCorpus, content_transformer(tolower))
View(taggedCorpus)
annotated_corpus <- lapply(taggedCorpus, annotateDocuments)
View(annotated_corpus)
colnames(annotated_corpus) <- make.names(colnames(annotated_corpus))
annotated_corpus$deceptive <- deceptive.opinion$deceptive
AnnotatedMatrix <- as.data.frame(as.matrix(annotated_corpus))
View(AnnotatedMatrix)
colnames(AnnotatedMatrix) <- make.names(colnames(AnnotatedMatrix))
AnnotatedMatrix$deceptive <- deceptive.opinion$deceptive
taggedCorpus = VCorpus(VectorSource(deceptive.opinion$text))
taggedCorpus = tm_map(taggedCorpus, content_transformer(tolower))
annotated_corpus <- lapply(taggedCorpus, annotateDocuments)
AnnotatedMatrix <- as.data.frame(as.matrix(annotated_corpus))
View(AnnotatedMatrix)
colnames(AnnotatedMatrix) <- make.names(colnames(AnnotatedMatrix))
AnnotatedMatrix$deceptive <- deceptive.opinion$deceptive
View(Tagcorpus)
taggedCorpus = VCorpus(VectorSource(deceptive.opinion$text))
taggedCorpus <- lapply(taggedCorpus, scan_tokenizer)
annotated_corpus <- lapply(taggedCorpus, annotateDocuments)
AnnotatedMatrix <- as.data.frame(as.matrix(annotated_corpus))
View(AnnotatedMatrix)
colnames(AnnotatedMatrix) <- make.names(colnames(AnnotatedMatrix))
AnnotatedMatrix$deceptive <- deceptive.opinion$deceptive
View(annotated_corpus)
View(AnnotatedMatrix)
taggedCorpus = VCorpus(VectorSource(deceptive.opinion$text))
taggedCorpus <- lapply(taggedCorpus, scan_tokenizer)
annotated_corpus <- lapply(taggedCorpus, annotateDocuments)
taggedCorpus = VCorpus(VectorSource(annotated_corpus))
AnnotatedMatrix <- as.data.frame(as.matrix(taggedCorpus))
View(AnnotatedMatrix)
colnames(AnnotatedMatrix) <- make.names(colnames(AnnotatedMatrix))
AnnotatedMatrix$deceptive <- deceptive.opinion$deceptive
library(udpipe)
View(AnnotatedMatrix)
AnnotatedMatrix <- as.data.frame(as.matrix(taggedCorpus))
View(AnnotatedMatrix)
colnames(AnnotatedMatrix) <- make.names(colnames(AnnotatedMatrix))
AnnotatedMatrix$deceptive <- deceptive.opinion$deceptive
AnnotatedMatrix <- as.data.frame(as.matrix(taggedCorpus))
View(AnnotatedMatrix)
colnames(AnnotatedMatrix) <- make.names(colnames(AnnotatedMatrix))
AnnotatedMatrix[-c(deceptive), ]
AnnotatedMatrix[-c(1601), ]
View(AnnotatedMatrix)
AnnotatedMatrix[-c(1601, ]
AnnotatedMatrix[-c(1601), ]
AnnotatedMatrix= AnnotatedMatrix[-c(1601), ]
View(AnnotatedMatrix)
View(AnnotatedMatrix)
taggedCorpus = VCorpus(VectorSource(deceptive.opinion$text))
taggedCorpus <- lapply(taggedCorpus, scan_tokenizer)
annotated_corpus <- lapply(taggedCorpus, annotateDocuments)
taggedCorpus = VCorpus(VectorSource(annotated_corpus))
AnnotatedMatrix <- as.data.frame(as.matrix(taggedCorpus))
View(AnnotatedMatrix)
colnames(AnnotatedMatrix) <- make.names(colnames(AnnotatedMatrix))
AnnotatedMatrix <- as.data.frame(as.matrix(taggedCorpus))
View(AnnotatedMatrix)
View(AnnotatedMatrix)
#model <- udpipe_download_model(language = "english")
udmodel_english <- udpipe_load_model(file = 'english-ud-2.0-170801.udpipe')
model <- udpipe_download_model(language = "english")
udmodel_english <- udpipe_load_model(file = 'english-ud-2.0-170801.udpipe')
s <- udpipe_annotate(udmodel_english, deceptive.opinion$text)
model <- udpipe_download_model(language = "english")
udmodel_english <- udpipe_load_model(file = 'english-ud-2.0-170801.udpipe')
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)
udmodel_english <- udpipe_load_model(file = 'english-ud-2.0-170801.udpipe')
x <- udpipe_annotate(ud_model, s)
x <- udpipe_annotate(ud_model,deceptive.opinion$text )
View(x)
x[["conllu"]]
library(udpipe)
library(openNLPdata)
library(qdap)
library(wordcloud)
library(tokenizers)
library(tm)
library(SnowballC)
library(gamlr)
library(dplyr)
library(openNLP)
library(glm2)
library(tidyr)
library(tm)
library(tidyselect)
library(tokenizers)
library(wordcloud)
library(dplyr)
library(topicmodels)
library(dplyr)
s <- udpipe_annotate(ud_model, deceptive.opinion$text)
model <- udpipe_download_model(language = "english")
library(udpipe)
library(openNLPdata)
library(qdap)
library(wordcloud)
library(tokenizers)
library(tm)
library(SnowballC)
library(gamlr)
library(dplyr)
library(openNLP)
library(glm2)
library(tidyr)
library(tm)
library(tidyselect)
library(tokenizers)
library(wordcloud)
library(dplyr)
library(topicmodels)
library(dplyr)
if (file.exists("english-ud-2.0-170801.udpipe"))
ud_model <- udpipe_load_model(file = "english-ud-2.0-170801.udpipe") else {
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)
}
x <- udpipe_annotate(ud_model, deceptive.opinion$text)
x <- as.data.frame(x)
table(x$upos)
load("~/FYP_LR_Prototype/.RData")
View(deceptiveRev)
dx <- udpipe_annotate(ud_model, deceptiveRev$text)
dx <- as.data.frame(dx)
library(dplyr)
library(topicmodels)
library(dplyr)
library(wordcloud)
library(tokenizers)
library(tidyselect)
library(tm)
library(tidyr)
library(glm2)
library(openNLP)
library(dplyr)
library(gamlr)
library(SnowballC)
library(tm)
library(tokenizers)
library(wordcloud)
library(qdap)
library(openNLPdata)
library(udpipe)
library(dplyr)
if (file.exists("english-ud-2.0-170801.udpipe"))
ud_model <- udpipe_load_model(file = "english-ud-2.0-170801.udpipe") else {
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)
}
dx <- udpipe_annotate(ud_model, deceptiveRev$text)
dx <- as.data.frame(dx)
table(dx$upos)
tx <- udpipe_annotate(ud_model, TruthfulRev$text)
tx <- as.data.frame(tx)
table(tx$upos)
library(ggplot2)
View(dx)
View(dx)
table(x$sentence_id, x$upos)
table(dx$sentence_id, dx$upos)
table(dx$paragraph_id, dx$upos)
load("~/FYP_LR_Prototype/.RData")
savehistory("~/FYP_LR_Prototype/fyp 3.Rhistory")
